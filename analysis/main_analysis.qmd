```{r}
library(tidyverse)
library(here)
library(glue)
library(viridis)
library(tidytext)
library(patchwork)
library(tidyr)
library(scales)
library(forcats)
library(stringr)
source("helpers.R")
```

```{r}
df_cleaned <- read.csv(here("data", "all_contexts_cleaned.csv")) 
#df_sustained_activities %>%
 # filter(duration_seconds >= 60)
  #read.csv(here("data", "all_contexts_cleaned.csv"))
df_cleaned_seconds <- df_cleaned |>
  rowwise() |>
  mutate(frame_num = list(seq(start_time+1, end_time))) |>
  unnest(frame_num) |>
  filter(Activity != "")
recordings <- read_csv(here("data/recordings_processed.csv")) |> select(-start_time)

nrow(df_cleaned |> filter(!is.na(gopro_video_id)))/360
```
# Combine annotations
```{r}
bind_annotations <- function(input_video_id,
                             objects = "random",
                             tokens = "random",
                             k = 5, threshold = 5) {
  # activities
  vid_activities <- df_cleaned |>
    filter(superseded_gcp_name_feb25 == input_video_id)
  
   vid_activities_cleaned <- vid_activities |>
    select(superseded_gcp_name_feb25, start_time, end_time, 
           annotation = Activity, locations_avg) |>
    mutate(start_time = as.numeric(start_time),
           end_time = as.numeric(end_time)) |>
    # Create a row for each second within the 10-second clip
    rowwise() |>
    reframe(
      superseded_gcp_name_feb25 = superseded_gcp_name_feb25,
      timestamp = seq(start_time, end_time, by = 1),
      annotation = annotation,
      location = locations_avg,
      stream = "activities"
    )
   
   vid_activities_chunked <- vid_activities_cleaned |>
    select(-location)
  
  # chunked locations (10-second clips)
  vid_locations_chunks <- vid_activities_cleaned |>
    mutate(
      annotation = location,
      stream = "locations"
    )

  # combine
  vid_full <- list(vid_activities_chunked,
                   vid_locations_chunks) |> 
    list_rbind()
}
```


# Kosie Plot
```{r}
STREAM_COLORS <- c("Objects" = "#e06666",
                   "Activities" = "#f6b26b",
                   "Frame locations" = "#90EE90",
                   "Locations"="#6B8E23",
                   "Speech" = "#76a5af")

make_kosie_plot <- function(full_annotations) {
  full_annotations |> 
    mutate(stream = str_to_sentence(stream),
           annotation = annotation |> fct_infreq() |> fct_rev()) |> 
    #filter(stream == "Chunk locations" | stream == "Frame locations" | stream == "Activities") |>
    ggplot(aes(x = timestamp,
               y = annotation,
               fill = stream)) +
    geom_tile(width = 1, height = 1) +
    facet_grid(stream ~ .,
               scales = "free_y",
               space = "free_y") +
    labs(x = "Elapsed video time (s)",
         y = "Annotation") +
    scale_fill_manual(values = STREAM_COLORS) +
    theme(legend.position = "none") +
    theme_minimal(base_size = 26) +
    theme(
      legend.position = "none",
      strip.text = element_text(size = 26)  # Increase this value to your preference
    )
    
}
```

## just random ids for now
```{r}
filtered_superseded_gcp_ids <- df_cleaned |>
  group_by(superseded_gcp_name_feb25) |>
  filter(sum(Activity == "reading") > n()/2) |> 
  distinct(superseded_gcp_name_feb25)
random_video_id <- sample(filtered_superseded_gcp_ids$superseded_gcp_name_feb25, 1)
kosie_plot <- make_kosie_plot(bind_annotations("00510002_2024-08-20_5_5660d1ff71", threshold = 10))
print(kosie_plot)
ggsave(here("data/kosie_plot.pdf"), kosie_plot, width=10, height=7,bg="white")
# illustrate some variability
```


```{r}
df_all <- read.csv(here("data", "all_contexts.csv")) 
df_missing <- read.csv(here("data", "all_contexts.csv")) |> filter(Location == "")    |> mutate(superseded_gcp_name_feb25 = sub("_processed.*", "", video_id),
         chunk_num = as.integer(sub(".*_(\\d+)\\.mp4", "\\1", basename(video_path))))

mean(sapply(str_split(df_cleaned$Video.description, " "), length))
```

# Constants and helpers
Setting a minimum number of continuous frames to count a location as a 'stable' location. 10 frames = 10 seconds.
```{r}
LOCATION_LENGTH <- 30

avg_age <- function(df) {
  df |> mutate(age_avg = str_extract_all(age_bin, "\\d+") %>% 
      lapply(as.numeric) %>% 
      sapply(function(x) mean(x)))
}


plot_subject_breakdown <- function(df, subject_df, x_var, y_var, group, input_title, x_lab, y_lab, use_size = TRUE, use_line=TRUE) {
  p <- ggplot(data = df, aes(x = .data[[x_var]], y = weighted_mean, group = 1))
  
  if (use_size && "total_hours" %in% names(subject_df)) {
    p <- p + geom_jitter(
      data = subject_df,
      aes(x = .data[[x_var]], y = .data[[y_var]], color = .data[[group]], size = total_hours),
      width = 0.1, height = 0, alpha = 0.5
    )
  } else {
    p <- p + geom_jitter(
      data = subject_df,
      aes(x = .data[[x_var]], y = .data[[y_var]], color = .data[[group]]),
      width = 0.1, height = 0, alpha = 0.5
    )
  }
  
  if (use_line) {
    p <- p + geom_line()
  }
  
  p  +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.1) +
    labs(
      title = input_title,
      x = x_lab,
      y = y_lab
    ) +
    theme_minimal() +
    guides(color = "none")
}
```

```{r}
contexts_avg <- df_cleaned_seconds |>
  filter(!is.na(location)) |>
  bin_age() |>
  rename(total_frame_count = total_count)
```

# Proportions plots
```{r}
props_data <- bind_rows(
  df_cleaned %>%
    count(Activity) %>%
    mutate(prop = n / sum(n),
           variable = "Activity",
           category = Activity),
  
  df_cleaned %>%
    count(Location) %>%
    mutate(prop = n / sum(n),
           variable = "Location",
           category = Location)
)


props_data <- props_data %>%
  group_by(variable) %>%
  mutate(category = reorder_within(category, -prop, variable)) %>%
  ungroup()

props_plot <- ggplot(props_data, aes(x = category, y = prop, fill = variable)) +
  geom_col() +
    coord_flip() +
   scale_y_continuous() +
  labs(title = "",
       x = NULL,
       y = "Proportion of detections") +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~variable, scales = "free_y") +
  scale_x_reordered() +
  scale_fill_manual(
    values = c(
      "Location" = location_color,
      "Activity" = activity_color
    )
  ) + theme_classic() +
    theme(
      strip.text = element_text(size = 26),
    # Axis text
    axis.text.x = element_text(size = 20,angle = 45, hjust = 1,),  # X-axis labels
    axis.text.y = element_text(size = 20),                         # Y-axis labels
    
    # Axis titles
    axis.title.x = element_text(size = 26, margin=margin(t=10)),
    axis.title.y = element_text(size = 30, margin=margin(r=10)),
    
    # Legend
    legend.position = "none",
  plot.margin = margin(t = 10, r = 10, b = 10, l = 5)
      ) 
props_plot
ggsave(here("figures/base_frequency.svg"),props_plot,  width=9.5, height=8, device="pdf")
ggsave(here("figures/base_frequency.png"),props_plot,  width=12, height=8, device="pdf")
```

## log props plot
```{r}
log_props_plot <- ggplot(props_data, aes(x = category, y = log(prop) + 10, fill = variable)) +
  geom_col() +
   scale_y_continuous(
    breaks = seq(0, 10, 2),
    labels = seq(-10, 0, 2)
  ) +
  labs(x = NULL,
       y = "log (proportion)") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~variable, scales = "free_x") +
  scale_x_reordered() +
  scale_fill_manual(
    values = c(
      "Location" = location_color,
      "Activity" = activity_color
    )
  )
log_props_plot
```

## Prop of locations within activities
```{r}
top_locations <- df_cleaned %>%
  mutate(Location = ifelse(Location == "deck", "outside", Location)) |>
  count(Location, sort = TRUE) |>
  slice_head(n = 6) |>  # Top 8 locations
  pull(Location)

top_locations <- c(top_locations, "garden")

df_prop <- df_cleaned %>%
  mutate(Location_grouped = ifelse(Location %in% top_locations, Location, "other")) %>%
  group_by(Activity, Location_grouped) %>%
  summarise(n = n(), .groups = "drop") %>%
  group_by(Activity) %>%
  mutate(prop = n / sum(n)) %>%   # calculate proportion per Activity
  ungroup() %>%
  arrange(desc(prop))

my_set2_no_orange_green <- c(
  "#75A7B4", # teal
  "#E78AC3", # pink
  "#FFD92F", # yellow
  "#8DA0CB", # blue
  "#A6CEE3", # light blue (from Set3)
  "#CAB2D6", # lavender (from Set3)
  "#FB9A99",  # soft red (from Set3)
  "#B3B3B3" # gray
)


df_prop_reordered <- df_prop %>%
  filter(Activity != "other") %>%
  group_by(Activity) %>%
  arrange(desc(prop)) %>%  # largest prop first
  mutate(
    # Make gray ("other") always first in stacking (bottom), others in descending order
    Location_grouped = fct_relevel(Location_grouped,
                                   "other",
                                   after = 0)
  ) %>%
  ungroup()

location_order <- props_data |>
  filter(variable == "Location") |>
  arrange(desc(prop)) |>
  pull(Location)

# Reorder factor globally so ggplot stacks correctly
df_prop_reordered <- df_prop %>%
  mutate(Location_grouped = factor(Location_grouped)) %>%
  group_by(Activity) %>%
  arrange(Activity, desc(prop)) %>% 
  group_by(Activity) %>%
  mutate(
    # First, reorder by prop in descending order
    Location_grouped = fct_reorder(Location_grouped, prop, .desc = TRUE),
    # Then move "Other" to the end
    Location_grouped = fct_relevel(Location_grouped, "other", after = Inf)
  ) %>%
  ungroup() |>
   mutate(
    Activity = fct_relevel(Activity, "other", after = Inf),
    Location_grouped = fct_relevel(Location_grouped, intersect(location_order,levels(Location_grouped))),
    Location_grouped = fct_relevel(Location_grouped, "other", after=Inf)
  )

# Plot
loc_props <- ggplot(df_prop_reordered, aes(x = Activity, y = prop, fill = Location_grouped)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = my_set2_no_orange_green) +
  labs(
    x = "Activity",
    y = "Proportion of activity in location",
    fill = "Location"
  ) +
  scale_y_continuous(limits=c(0,NA)) +
  theme_classic() +
  theme(
    # Axis text
    axis.text.x = element_text(angle = 45, hjust = 1, size = 19),  # X-axis labels
    axis.text.y = element_text(size = 22),                         # Y-axis labels
    
    # Axis titles
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 24, margin=margin(r=10)),
    
    # Legend
    legend.position = "right",
    legend.title = element_text(size = 24),
    legend.text = element_text(size = 20),
    legend.spacing.y = unit(0.6, "cm") 
      ) +
  guides()

print(loc_props)
ggsave(here("figures/loc_prop.png"), loc_props, width=12, height=7, bg = "white", device = "pdf")
```

combining proportion plots
```{r}
full_props_plot <- cowplot::plot_grid(
  props_plot, loc_props,
  labels = c("A", "B"),   # Add labels
  label_size = 36,        # Font size
  label_fontface = "bold",# Bold labels
  label_x = 0,            # Left align
  label_y = 1,            # Top align
  hjust = c(-0.2, 0.5), 
  rel_widths = c(1,1.3),
  vjust = 1.2,
  scale = 0.98
)

# Show the plot
print(full_props_plot)
ggsave(here("figures/full_props.png"), full_props_plot, width=20, height=12)
```

# sustained activities 
```{r}
df_sustained <- df_cleaned %>%
  mutate(
    duration_seconds = end_time - start_time,
    video_id = superseded_gcp_name_feb25
  ) %>%
  arrange(subject_id, video_id, start_time) %>%
  # Create groups for contiguous episodes with same activity and location
  group_by(subject_id, video_id) %>%
  mutate(
    # Check if current row is different from previous row
    activity_change = Activity != lag(Activity, default = ""),
    location_change = Location != lag(Location, default = ""),
    # Check if there's a temporal gap (assuming consecutive 10-second chunks)
    time_gap = start_time != lag(end_time, default = first(start_time)),
    # Any change triggers a new episode
    episode_change = activity_change | location_change | time_gap,
    # Create episode ID within each video
    episode_id = cumsum(episode_change)
  ) %>%
  # Now group by episode and combine chunks
  group_by(subject_id, video_id, episode_id, Activity, Location) %>%
  summarise(
    start_time = min(start_time),
    end_time = max(end_time),
    n_chunks = n(),
    .groups = 'drop'
  ) %>%
  mutate(
    duration_seconds = end_time - start_time,
    duration_minutes = duration_seconds / 60,
    # Create unique episode identifier across all data
    global_episode_id = paste(subject_id, video_id, episode_id, sep = "_")
  ) %>%
  filter(duration_seconds > 0) %>%
  arrange(subject_id, video_id, start_time)


df_sustained_activities <- df_cleaned %>%
  mutate(
    duration_seconds = end_time - start_time,
    video_id = superseded_gcp_name_feb25
  ) %>%
  arrange(subject_id, video_id, start_time) %>%
  # Create groups for contiguous episodes with same activity and location
  group_by(subject_id, video_id) %>%
  mutate(
    # Check if current row is different from previous row
    activity_change = Activity != lag(Activity, default = ""),
    # Check if there's a temporal gap (assuming consecutive 10-second chunks)
    time_gap = start_time != lag(end_time, default = first(start_time)),
    # Any change triggers a new episode
    episode_change = activity_change | time_gap,
    # Create episode ID within each video
    episode_id = cumsum(episode_change)
  ) %>%
  # Now group by episode and combine chunks
  group_by(subject_id, video_id, episode_id, Activity) %>%
  summarise(
    start_time = min(start_time),
    end_time = max(end_time),
    n_chunks = n(),
    .groups = 'drop'
  ) %>%
  mutate(
    duration_seconds = end_time - start_time,
    duration_minutes = duration_seconds / 60,
    # Create unique episode identifier across all data
    global_episode_id = paste(subject_id, video_id, episode_id, sep = "_")
  ) %>%
  filter(duration_seconds > 0) %>%
  arrange(subject_id, video_id, start_time)

print(paste("Original chunks:", nrow(df_cleaned)))
print(paste("Combined into sustained episodes with same activity and location:", nrow(df_sustained)))
print(paste("Combined into sustained episodes with same activity:", nrow(df_sustained_activities)))
print(paste("Total duration range:", round(min(df_sustained_activities$duration_seconds, na.rm = TRUE), 2), 
            "to", round(max(df_sustained$duration_seconds, na.rm = TRUE), 2), "seconds"))
print(paste("Mean episode duration:", round(mean(df_sustained_activities$duration_seconds, na.rm = TRUE), 2), "seconds"))
```

# sustained activities -- plot
```{r}
# Calculate total hours of data per subject for weighting
subject_hours <- df_sustained_activities %>%
  group_by(subject_id, Activity) %>%
  summarise(activity_hours = sum(duration_seconds) / 3600, .groups = 'drop') |>
  group_by(subject_id) |>
  mutate(total_hours = sum(activity_hours), .groups = 'drop')

# Calculate activity duration at subject level first
subject_activity_duration <- df_sustained_activities %>%
  group_by(subject_id, Activity) %>%
  summarise(
    mean_duration_sec = mean(duration_seconds),
    n_episodes = n(),
    .groups = 'drop'
  ) %>%
  left_join(subject_hours, by = c("subject_id", "Activity"))

# Calculate group-level statistics with weighting
activity_duration_weighted <- subject_activity_duration %>%
  group_by(Activity) %>%
  group_modify(~ weighted_ci_normal_df(
    .x,
    value_col = "mean_duration_sec",
    weight_col = "total_hours",
    group_col = NULL
  )) %>%
  ungroup() %>%
  # Add total sample size info
  left_join(
    subject_activity_duration %>%
      group_by(Activity) %>%
      summarise(
        n_subjects = n(),
        total_episodes = sum(n_episodes),
        .groups = 'drop'
      ),
    by = "Activity"
  )

# Get top 10 activities by mean duration
top_10_activities <- props_data %>%
  filter(variable=="Activity") |>
  arrange(desc(n)) %>%
  slice_head(n = 10) %>%
  pull(Activity)

# Filter data to top 10 activities
activity_durations_filtered <- activity_duration_weighted %>%
  filter(Activity %in% top_activities)

subject_activity_durations_filtered <- subject_activity_duration %>%
  filter(Activity %in% top_activities)
```

## weighted proportions and activity durations
```{r}
# Calculate total hours per participant
participant_hours <- df_cleaned %>%
  group_by(subject_id) %>%
  summarise(total_hours = n() / 360, .groups = 'drop')

# Calculate activity proportions at participant level
participant_activity_props <- df_cleaned %>%
  group_by(subject_id, Activity) %>%
  summarise(activity_hours = n() / 360, .groups = 'drop') %>%
  left_join(participant_hours, by = "subject_id") %>%
  mutate(activity_proportion = activity_hours / total_hours)

# Calculate weighted mean proportions across participants
activity_props_weighted <- participant_activity_props %>%
  group_by(Activity) %>%
  group_modify(~ weighted_ci_normal_df(
    .x,
    value_col = "activity_proportion",
    weight_col = "total_hours",
    group_col = NULL
  )) |>
  ungroup()

# Filter data for plotting
activity_props_filtered <- activity_props_weighted %>%
  filter(Activity %in% top_activities)

participant_props_filtered <- participant_activity_props %>%
  filter(Activity %in% top_activities)

# Create the plot
proportions_plot <- ggplot(activity_props_filtered, 
                          aes(x = reorder(Activity, -weighted_mean), 
                              y = weighted_mean, 
                              fill = Activity)) +
  geom_point(data = participant_props_filtered,
             aes(x = Activity, y = activity_proportion, 
                 size = activity_hours, color = Activity),
             alpha = 0.4, position = position_jitter(width = 0.2)) +
  
  geom_errorbar(aes(ymin = pmax(0, ci_lower), ymax = ci_upper),
                width = 0.6, alpha = 0.9) +
  geom_point(alpha=0.9, size=4) +
  labs(x = "Activity", 
       y = "Proportion of detections",
       size = "Total hours\nper participant") +
  theme_classic() +
  scale_y_continuous(limits = c(0, max(activity_props_filtered$weighted_mean) * 1.1)) +
  scale_fill_manual(values = setNames(activity_palette, top_activities), guide = "none") +
  scale_color_manual(values = setNames(activity_palette, top_activities), guide = "none") +
  scale_size_continuous(range = c(5, 15)) +
  theme(
  # Axis text
  axis.text.x = element_text(size = 24, angle=45,hjust=1),  # X-axis labels
  axis.text.y = element_text(size = 24),                         # Y-axis labels
  
  # Axis titles
 axis.title.x = element_blank(),
  axis.title.y = element_text(size = 28, margin = margin(r = 15)),
  
  # Legend
  legend.position = "none",
)

sustained_plot <- ggplot(activity_durations_filtered, aes(x = reorder(Activity, -weighted_mean), y = weighted_mean, fill=Activity)) +
    geom_point(data = subject_activity_durations_filtered, 
             aes(x = Activity, y = mean_duration_sec, size = activity_hours, color=Activity),
             alpha = 0.4, position = position_jitter(width = 0.2)) +
  geom_errorbar(aes(ymin = pmax(0, ci_lower), ymax = ci_upper),
                width = 0.6, alpha = 0.9) +
  geom_point(alpha=0.9, size=4) +
  labs(title = "",
       subtitle = "",
       x = "Activity", y = "Mean duration (seconds)",
       size = "Total hours of data\nper participant and \nactivity") +
  theme_classic() +
geom_hline(yintercept = 10, linetype = "dotted", color = "black", size = 0.8) +
  scale_y_continuous(limits = c(5, 100), breaks=seq(10, 100, by = 20)) +
   scale_fill_manual(values = setNames(activity_palette, top_activities), guide="none") +
  scale_color_manual(values = setNames(activity_palette, top_activities), guide="none") +
  scale_size_continuous(range = c(7, 17)) +
  theme(
  # Axis text
  axis.text.x = element_text(size = 24, angle=45, hjust=1),  # X-axis labels
  axis.text.y = element_text(size = 24),                         # Y-axis labels
  
  # Axis titles
  axis.title.x = element_blank(),
  axis.title.y = element_text(size = 28, margin = margin(r = 15)),
  
  # Legend
  legend.position = c(0.85, 0.7), 
  legend.title = element_text(size = 22),
  legend.text = element_text(size = 20),
)

subject_weighted_plot <- cowplot::plot_grid(
  proportions_plot, sustained_plot,
  labels = c("A", "B"),   # Add labels
  label_size = 28,        # Font size
  label_fontface = "bold",# Bold labels
  label_x = 0,            # Left align
  label_y = 1,            # Top align
  hjust = -0.2,           # Adjust horizontal position
  vjust = 1.2             # Adjust vertical position
)

# Show the plot
print(subject_weighted_plot)
ggsave(here("figures/subject_weighted.png"), subject_weighted_plot, width=20, height=9)
```


# Activity co-occurrences within videos (all exploratory)
```{r}
activity_pairs <- df_sustained_activities %>%
  group_by(video_id) %>%
  filter(n_distinct(Activity) > 1) %>%   # Only videos with multiple activities
  summarise(activities = list(unique(Activity)), .groups = 'drop') %>%
  rowwise() %>%
  mutate(pairs = list(combn(activities, 2, simplify = FALSE))) %>%
  unnest(pairs) %>%
  mutate(
    act_1 = map_chr(pairs, ~ .x[1]),
    act_2 = map_chr(pairs, ~ .x[2])
  ) %>%
  # enforce an ordering so (A, B) == (B, A)
  mutate(
    activity1 = pmin(act_1, act_2),
    activity2 = pmax(act_1, act_2)
  ) %>%
  count(activity1, activity2) %>%
  # Add reverse pairs for symmetric matrix
  bind_rows(
    ., 
    select(., activity1 = activity2, activity2 = activity1, n)
  ) %>%
  # Add diagonal (self-pairs)
  bind_rows(
    df_sustained %>% 
      group_by(video_id, Activity) %>% 
      slice(1) %>% 
      ungroup() %>%
      count(Activity) %>%
      rename(activity1 = Activity) %>%
      mutate(activity2 = activity1)
  )

diagonal_counts <- activity_pairs %>%
  filter(activity1 == activity2) %>%
  select(activity1, diag_n = n)

# Join and compute proportion
activity_pairs_prop <- activity_pairs %>%
  left_join(diagonal_counts, by = c("activity1")) %>%
  mutate(proportion = n / diag_n) %>%
  select(activity1, activity2, proportion)

activity_pairs_sustained <- df_sustained_activities %>%
  filter(duration_seconds >= 60) %>%
  group_by(video_id) %>%
  filter(n_distinct(Activity) > 1) %>%   # Only videos with multiple activities
  summarise(activities = list(unique(Activity)), .groups = 'drop') %>%
  rowwise() %>%
  mutate(pairs = list(combn(activities, 2, simplify = FALSE))) %>%
  unnest(pairs) %>%
  mutate(
    act_1 = map_chr(pairs, ~ .x[1]),
    act_2 = map_chr(pairs, ~ .x[2])
  ) %>%
  # enforce an ordering so (A, B) == (B, A)
  mutate(
    activity1 = pmin(act_1, act_2),
    activity2 = pmax(act_1, act_2)
  ) %>%
  count(activity1, activity2) %>%
  # Add reverse pairs for symmetric matrix
  bind_rows(
    ., 
    select(., activity1 = activity2, activity2 = activity1, n)
  ) %>%
  # Add diagonal (self-pairs)
  bind_rows(
    df_sustained %>% 
      group_by(video_id, Activity) %>% 
      slice(1) %>% 
      ungroup() %>%
      count(Activity) %>%
      rename(activity1 = Activity) %>%
      mutate(activity2 = activity1)
  )

diagonal_counts_sustained <- activity_pairs_sustained %>%
  filter(activity1 == activity2) %>%
  select(activity1, diag_n = n)

# Join and compute proportion
activity_pairs_prop_sustained <- activity_pairs_sustained %>%
  left_join(diagonal_counts_sustained, by = c("activity1")) %>%
  mutate(proportion = n / diag_n) %>%
  select(activity1, activity2, proportion)

# Location co-occurrences within videos
location_pairs <- df_sustained %>%
  group_by(video_id) %>%
  filter(n_distinct(Location) > 1) %>%  # Only videos with multiple locations
  summarise(locations = list(unique(Location)), .groups = 'drop') %>%
  rowwise() %>%
  mutate(
    pairs = list(combn(locations, 2, simplify = FALSE))
  ) %>%
  unnest(pairs) %>%
  mutate(
    location1 = map_chr(pairs, ~.x[1]),
    location2 = map_chr(pairs, ~.x[2])
  ) %>%
  count(location1, location2) %>%
  # Add reverse pairs for symmetric matrix
  bind_rows(
    ., 
    select(., location1 = location2, location2 = location1, n)
  ) %>%
  # Add diagonal
  bind_rows(
    df_sustained %>% 
      group_by(video_id, Location) %>% 
      slice(1) %>% 
      ungroup() %>%
      count(Location) %>%
      rename(location1 = Location) %>%
      mutate(location2 = location1)
  )

# Activity-Location co-occurrence matrix
all_activities <- unique(df_sustained$Activity)
all_locations <- unique(df_sustained$Location)

activity_location_matrix <- df_sustained %>%
  distinct(video_id) %>%
  crossing(
    Activity = all_activities,
    Location = all_locations
  ) %>%
  left_join(
    df_sustained %>%
      group_by(video_id, Activity, Location) %>%
      summarise(present = 1, .groups = 'drop'),
    by = c("video_id", "Activity", "Location")
  ) %>%
  replace_na(list(present = 0)) %>%
  group_by(Activity, Location) %>%
  summarise(n_videos = sum(present), .groups = 'drop')

excluded_activities <- c() #"crying", "nursing", "gardening", "other")
p1a <- ggplot( activity_pairs_prop %>%
    filter(!activity1 %in% excluded_activities,
           !activity2 %in% excluded_activities), aes(x = activity1, y = activity2, fill = proportion)) +
  geom_tile(size = 0.5) +
  scale_fill_viridis(name = "Proportion of videos with activity", trans = "sqrt", option="A", direction=-1, begin=0.3) +
  labs(title = "Activity Co-occurrences Within Videos",
       x = "Activity", y = "Activity") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5)
  )
print(p1a)
```

```{r}
p1a <- ggplot( activity_pairs_prop_sustained %>%
    filter(!activity1 %in% excluded_activities,
           !activity2 %in% excluded_activities), aes(x = activity1, y = activity2, fill = proportion)) +
  geom_tile(size = 0.5) +
  scale_fill_viridis(name = "Proportion of videos with activity", trans = "sqrt", option="A", direction=-1, begin=0.3) +
  labs(title = "Sustained Activity Co-occurrences Within Videos",
       x = "Activity", y = "Activity") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5)
  )
# Print heatmaps separately for better readability
print(p1a)
```
## surprisal
```{r}
excluded_activities <- c() #c("crying", "nursing", "gardening", "other")

# Get the correct activity ordering based on total counts from df_cleaned
activity_totals <- df_cleaned %>%
  filter(!Activity %in% excluded_activities) %>%
  count(Activity, name = "total_count") %>%
  arrange(desc(total_count))

activity_order_custom <- c("playing", "reading", "drawing", "watching tv", "music time", "dancing",
                           "eating", "drinking", "cleaning", "cooking")

obs_matrix <- activity_pairs_prop %>%
  filter(!activity1 %in% excluded_activities,
         !activity2 %in% excluded_activities) %>%
  pivot_wider(names_from = activity2, values_from = proportion, values_fill = 0) %>%
  column_to_rownames("activity1") %>%
  as.matrix()

# Compute remaining activities once
remaining_activities <- setdiff(rownames(obs_matrix), activity_order_custom)

# Reorder rows and columns together
obs_matrix <- obs_matrix[
  c(activity_order_custom, remaining_activities[order(rowSums(obs_matrix[remaining_activities, ]), decreasing = FALSE)]),
  c(activity_order_custom, remaining_activities[order(rowSums(obs_matrix[remaining_activities, ]), decreasing = FALSE)])
]

# mutual information
# treat the data as graph not a matrix, network
# Create off-diagonal matrix (exclude diagonal from all calculations)
off_diag_matrix <- obs_matrix
diag(off_diag_matrix) <- 0

# Compute expected counts using only off-diagonal values
row_tot <- rowSums(off_diag_matrix, na.rm = TRUE)
col_tot <- colSums(off_diag_matrix, na.rm = TRUE)
grand_tot <- sum(off_diag_matrix, na.rm = TRUE)

expected <- outer(row_tot, col_tot) / grand_tot

# Standardized residuals (only for off-diagonal elements)
std_resid <- (off_diag_matrix - expected) / sqrt(pmax(expected, 1e-9))

# Set diagonal to NA for visualization
diag(std_resid) <- NA

# Convert to long format
std_resid_df <- as.data.frame(as.table(std_resid))
colnames(std_resid_df) <- c("activity1", "activity2", "std_resid")

# Remove diagonal entries (NA values) from the plot data
std_resid_df <- std_resid_df %>%
  #mutate(std_resid = ifelse(activity1 == activity2, 0, std_resid)) |>
  filter(!is.na(std_resid))

# Plot heatmap
ggplot(std_resid_df, aes(x = activity1, y = activity2, fill = std_resid)) +
  geom_tile(color = "white", size = 0.5) +
  #scale_fill_viridis_c(option = "B", direction = -1, begin = 0.1) +
  #scale_fill_brewer(palette="BrBG") +
  #scale_fill_gradient2(mid="white", low=viridis_pal(option="A")[1], high=viridis_pal(option="A")[8])+
  scale_fill_gradient2(high = "darkred", mid = "white", low = "darkblue") +
  labs(title = "Standardized residuals of activity co-occurrence proportions",
       x = "Original activity", y = "Co-occurring activity",
       fill = "Standardized\nResidual") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5),
    legend.position = "right",
     panel.grid = element_blank()
  )
```

five minute chunking
## hierarchical clustering
```{r}
std_resid[is.na(std_resid)] <- 1

hcluster <- hclust(as.dist(1-std_resid), method="average")
hcluster$order
colnames(std_resid)[hcluster$order]
std_resid_df_new <- std_resid_df
std_resid_df_new$activity1 <- fct_relevel(std_resid_df$activity1, colnames(std_resid)[hcluster$order])
std_resid_df_new$activity2 <- fct_relevel(std_resid_df$activity2, colnames(std_resid)[hcluster$order])

ggplot(std_resid_df_new, aes(x = activity1, y = activity2, fill = std_resid)) +
  geom_tile(color = "white", size = 0.5) +
  #scale_fill_viridis_c(option = "B", direction = -1, begin = 0.1) +
  #scale_fill_brewer(palette="BrBG") +
  #scale_fill_gradient2(mid="white", low=viridis_pal(option="A")[1], high=viridis_pal(option="A")[8])+
  scale_fill_gradient2(high = "darkred", mid = "white", low = "darkblue") +
  labs(title = "Standardized residuals of activity co-occurrence proportions",
       x = "Original activity", y = "Co-occurring activity",
       fill = "Standardized\nResidual") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5),
    legend.position = "right",
     panel.grid = element_blank()
  )
```

## PMI
```{r}
#log(p(x,y)/p(x)*p(y))
activity_pairs_pmi <- activity_pairs |>
  left_join(diagonal_counts, by=c("activity1"="activity1")) |>
  rename(n1 = diag_n) |>
  left_join(diagonal_counts, by=c("activity2"="activity1")) |>
  rename(n2 = diag_n) |>
  mutate(total_num_videos = length(unique(df_cleaned$superseded_gcp_name_feb25)),
         p_activity1 = n1/sum(total_num_videos),
         p_activity2 = n2/sum(total_num_videos),
         p_activities = n/sum(total_num_videos),
         pmi = log(p_activities / (p_activity1 * p_activity2)))

filter_out_categories <- c("crying", "nursing")
activity_pairs_pmi <- activity_pairs_pmi |>
  filter(!(activity1 %in% filter_out_categories) & !(activity2 %in% filter_out_categories))
# |> filter(activity1 != activity2) 

pmi_matrix <- activity_pairs_pmi |>
  select(activity1, activity2, pmi) |>
  pivot_wider(names_from = activity2, values_from = pmi, values_fill = 0) %>%
  column_to_rownames("activity1") %>%
  as.matrix()

hcluster_pmi <- hclust(as.dist(-pmi_matrix), method="average")
hcluster_pmi$order
colnames(pmi_matrix)[hcluster_pmi$order]
pmi_ordered <- activity_pairs_pmi
pmi_ordered$activity1 <- fct_relevel(activity_pairs_pmi$activity1, colnames(pmi_matrix)[hcluster_pmi$order])
pmi_ordered$activity2 <- fct_relevel(activity_pairs_pmi$activity2, colnames(pmi_matrix)[hcluster_pmi$order])

ggplot(pmi_ordered, aes(x = activity1, y = activity2, fill = pmi)) +
  geom_tile(color = "white", size = 0.5) +
  #scale_fill_viridis_c(option = "B", direction = -1, begin = 0.1) +
  #scale_fill_brewer(palette="BrBG") +
  #scale_fill_gradient2(mid="white", low=viridis_pal(option="A")[1], high=viridis_pal(option="A")[8])+
  scale_fill_gradient2(high = "darkred", mid = "white", low = "darkblue", midpoint=mean(pmi_ordered$pmi)) +
  labs(title = "Pointwise mutual information across activities",
       x = "Activity", y = "Activity",
       fill = "PMI") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5),
    legend.position = "right",
     panel.grid = element_blank()
  )
```

```{r}
activity_pairs <- df_sustained_activities %>%
  # self-join within video_id to compare activities
  inner_join(df_sustained_activities, by = "video_id", suffix = c("_1", "_2")) %>%
  # ensure distinct pairs (avoid duplicate rows and self-joins unless same activity)
  filter(Activity_1 <= Activity_2) %>%
  # keep only pairs within 5 minutes
  filter(abs(start_time_1 - start_time_2) <= 300) %>%
  # rename for consistency
  transmute(
    activity1 = Activity_1,
    activity2 = Activity_2
  ) %>%
  count(activity1, activity2) %>%
  # add reverse pairs for symmetric matrix
  bind_rows(
    .,
    select(., activity1 = activity2, activity2 = activity1, n)
  ) %>%
  # add diagonal (self-pairs)
  bind_rows(
    df_sustained_activities %>%
      group_by(video_id, Activity) %>%
      slice(1) %>%
      ungroup() %>%
      count(Activity) %>%
      rename(activity1 = Activity) %>%
      mutate(activity2 = activity1)
  ) |>
  distinct(activity1, activity2, .keep_all=TRUE)

# diagonal counts for proportion
diagonal_counts <- activity_pairs %>%
  filter(activity1 == activity2) %>%
  select(activity1, diag_n = n)

# join & compute proportions
activity_pairs_prop <- activity_pairs %>%
  left_join(diagonal_counts, by = "activity1") %>%
  mutate(proportion = n / diag_n) %>%
  select(activity1, activity2, proportion)

# pearson's correlation in video
# z-scoring in some way
```


```{r}
# Average duration by activity with 95% CI
summarized_data <- function(data, x_var, y_var, group_var) {
  return(data %>%
           group_by_at(c(x_var, group_var)) %>%
           summarise(mean_value = mean(.data[[y_var]], na.rm = TRUE),
                     sd_value = sd(.data[[y_var]], na.rm = TRUE),
                     n = n(),
                     se = sd_value / sqrt(n()),
                     ci_lower = mean_value - qt(1 - (0.05 / 2), n - 1) * se,
                     ci_upper = mean_value + qt(1 - (0.05 / 2), n - 1) * se,
                     .groups = 'drop')
  )
}
activity_duration <-
  df_sustained_activities %>%
  group_by(Activity) %>%
  summarise(
    mean_duration_sec = mean(duration_seconds),
    sd_duration_sec = sd(duration_seconds),
    n_episodes = n(),
    se_duration_sec = sd_duration_sec / sqrt(n_episodes),
    # 95% CI
    ci_lower = mean_duration_sec - qt(0.975, n_episodes - 1) * se_duration_sec,
    ci_upper = mean_duration_sec + qt(0.975, n_episodes - 1) * se_duration_sec,
    .groups = 'drop'
  )
p3a <- ggplot(activity_duration, aes(x = reorder(Activity, mean_duration_sec), y = mean_duration_sec)) +
  geom_col(fill = activity_color, alpha = 0.7) +
  geom_errorbar(aes(ymin = pmax(0, ci_lower), ymax = ci_upper),
                width = 0.2, alpha = 0.8) +
  coord_flip() +
  labs(title = "Mean Episode Duration by Activity (95% CI)",
       x = "Activity", y = "Mean Duration (seconds)") +
  theme_minimal()

# Average duration by location with 95% CI
location_duration <- df_sustained %>%
  group_by(Location) %>%
  summarise(
    mean_duration_sec = mean(duration_seconds),
    sd_duration_sec = sd(duration_seconds),
    n_episodes = n(),
    se_duration_sec = sd_duration_sec / sqrt(n_episodes),
    # 95% CI
    ci_lower = mean_duration_sec - qt(0.975, n_episodes - 1) * se_duration_sec,
    ci_upper = mean_duration_sec + qt(0.975, n_episodes - 1) * se_duration_sec,
    .groups = 'drop'
  )

p3a <- ggplot(activity_duration, aes(x = reorder(Activity, mean_duration_sec), y = mean_duration_sec)) +
  geom_col(fill = activity_color, alpha = 0.7) +
  geom_errorbar(aes(ymin = pmax(0, ci_lower), ymax = ci_upper),
                width = 0.2, alpha = 0.8) +
  coord_flip() +
  labs(title = "Mean Episode Duration by Activity (95% CI)",
       x = "Activity", y = "Mean Duration (seconds)") +
  theme_minimal()

p3b <- ggplot(location_duration, aes(x = reorder(Location, mean_duration_sec), y = mean_duration_sec)) +
  geom_col(fill = location_color, alpha = 0.7) +
  geom_errorbar(aes(ymin = pmax(0, ci_lower), ymax = ci_upper),
                width = 0.2, alpha = 0.8) +
  coord_flip() +
  labs(title = "Mean Episode Duration by Location (95% CI)",
       x = "Location", y = "Mean Duration (seconds)") +
  theme_minimal()

p3a <- ggplot(activity_duration, aes(x = reorder(Activity, mean_duration_sec), y = mean_duration_sec)) +
  geom_col(fill = activity_color, alpha = 0.7) +
  geom_errorbar(aes(ymin = pmax(0, ci_lower), ymax = ci_upper),
                width = 0.2, alpha = 0.8) +
  coord_flip() +
  labs(title = "Mean Episode Duration by Activity (95% CI)",
       x = "Activity", y = "Mean Duration (seconds)") +
  theme_minimal()
print(p3a)
```




```{r}
df_sustained_activities_top10 <- df_sustained_activities %>%
  filter(Activity %in% top_10_activities,
         duration_seconds >= 10, duration_seconds <= 80)

# Create duration bins (e.g., 10-second intervals)
df_sustained_activities_top10 <- df_sustained_activities_top10 %>%
  mutate(duration_bin = cut(duration_seconds, 
                           breaks = seq(10, 80, by = 10),
                           include.lowest = TRUE,
                           labels = c("10-20", "21-30", "31-40", "41-50", 
                                     "51-60", "61-70", "71-80")))

# Calculate proportions within each duration bin
activity_props_by_duration <- df_sustained_activities_top10 %>%
  group_by(duration_bin, Activity) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(duration_bin) %>%
  mutate(
    total_in_bin = sum(count),
    proportion = count / total_in_bin
  ) %>%
  ungroup()

# Create a color palette for the top 10 activities
p3b <- ggplot(activity_props_by_duration, aes(x = duration_bin, y = proportion, 
                                              fill = Activity, group = Activity)) +
  geom_area(alpha = 0.7, position = "fill") +
  labs(title = "Activity Proportions by Episode Duration",
       subtitle = "How relative proportions of top 10 activities change with episode length",
       x = "Episode Duration (seconds)", 
       y = "Proportion of Activities",
       fill = "Activity") +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 100)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right",
        legend.key.size = unit(0.5, "cm")) +
  guides(fill = guide_legend(ncol = 1))

# Alternative version showing trend lines instead of stacked areas
p3b_lines <- ggplot(activity_props_by_duration, aes(x = as.numeric(duration_bin), 
                                                    y = proportion, color = Activity)) +
  geom_line(size = 1.2, alpha = 0.8) +
  geom_point(size = 2, alpha = 0.8) +
  #scale_color_manual(values = activity_palette) +
  scale_x_continuous(breaks = 1:7, 
                     labels = c("10-20", "21-30", "31-40", "41-50", 
                               "51-60", "61-70", "71-80")) +
  labs(title = "Activity Proportion Trends by Episode Duration",
       subtitle = "How proportions of top 10 activities change with episode length",
       x = "Episode Duration (seconds)", 
       y = "Proportion of Activities",
       color = "Activity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right") +
  guides(color = guide_legend(ncol = 1))

# Combine plots into a panel
combined_plot <- p3a / p3b_lines
combined_plot <- combined_plot + plot_annotation(
  title = "Activity Duration Analysis: Top 10 Activities",
  theme = theme(plot.title = element_text(size = 16, hjust = 0.5))
)

# Display the combined plot
print(combined_plot)
```
duration of playing activity
```{r}
playing_duration_plot <- df_sustained_activities_top10 |> 
  filter(Activity == "playing") |>
  ggplot(aes(x = duration_seconds)) +
  geom_histogram(binwidth = 10, 
                 fill = "#3498db", 
                 color = "white", 
                 alpha = 0.8) +
  scale_x_continuous(
    breaks = seq(0, max(df_sustained_activities_top10$duration_seconds[df_sustained_activities_top10$Activity == "playing"], na.rm = TRUE), 10)
  ) +
  labs(
    title = "Distribution of Playing Episode Durations",
    x = "Duration (seconds)",
    y = "Number of Episodes"
  ) +
  theme_minimal() 

playing_duration_plot
```

1. How much does this change when you get rid of the location episode
2. Within-subject and then dot for every subject
3. Individual dot in alpha 0.2, non-transparent, weight by number of hours of data per subject
4. Restrict to activities that had x amount of data in them

```{r}
p1b <- ggplot(location_pairs, aes(x = location1, y = location2, fill = n)) +
  geom_tile(color = "white", size = 0.5) +
  scale_fill_viridis_c(name = "Videos", trans = "sqrt") +
  labs(title = "Location Co-occurrences Within Videos",
       x = "Location", y = "Location") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5)
  )

p1c <- ggplot(activity_location_matrix, aes(x = Activity, y = Location, fill = n_videos)) +
  geom_tile(color = "white", size = 0.5) +
  scale_fill_viridis_c(name = "Videos", trans = "sqrt") +
  labs(title = "Activity-Location Co-occurrences Within Videos",
       x = "Activity", y = "Location") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(hjust = 0.5)
  )

# Activity distribution by subject
activity_by_subject <- df_sustained %>%
  group_by(subject_id, Activity) %>%
  summarise(
    total_duration_sec = sum(duration_seconds),
    n_episodes = n(),
    .groups = 'drop'
  ) %>%
  group_by(subject_id) %>%
  mutate(
    prop_duration = total_duration_sec / sum(total_duration_sec),
    prop_episodes = n_episodes / sum(n_episodes)
  )

# Location distribution by subject
location_by_subject <- df_sustained %>%
  group_by(subject_id, Location) %>%
  summarise(
    total_duration_sec = sum(duration_seconds),
    n_episodes = n(),
    .groups = 'drop'
  ) %>%
  group_by(subject_id) %>%
  mutate(
    prop_duration = total_duration_sec / sum(total_duration_sec),
    prop_episodes = n_episodes / sum(n_episodes)
  )

# Create Plot 2: Individual differences
p2a <- ggplot(activity_by_subject, aes(x = subject_id, y = prop_duration, fill = Activity)) +
  geom_col(position = "stack") +
  scale_fill_viridis_d() +
  labs(title = "Activity Duration Proportions by Subject",
       x = "Subject ID", y = "Proportion of Total Duration") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p2b <- ggplot(location_by_subject, aes(x = subject_id, y = prop_duration, fill = Location)) +
  geom_col(position = "stack") +
  scale_fill_brewer(type = "qual", palette = "Set2") +
  labs(title = "Location Duration Proportions by Subject",
       x = "Subject ID", y = "Proportion of Total Duration") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Activity diversity by subject (using Shannon entropy)
activity_diversity <- activity_by_subject %>%
  group_by(subject_id) %>%
  summarise(
    shannon_entropy = -sum(prop_duration * log(prop_duration + 1e-10)),
    n_activities = n(),
    .groups = 'drop'
  )

location_diversity <- location_by_subject %>%
  group_by(subject_id) %>%
  summarise(
    shannon_entropy = -sum(prop_duration * log(prop_duration + 1e-10)),
    n_locations = n(),
    .groups = 'drop'
  )

p2c <- ggplot(activity_diversity, aes(x = subject_id, y = shannon_entropy)) +
  geom_col(fill = "coral", alpha = 0.7) +
  labs(title = "Activity Diversity by Subject (Shannon Entropy)",
       x = "Subject ID", y = "Shannon Entropy") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p2d <- ggplot(location_diversity, aes(x = subject_id, y = shannon_entropy)) +
  geom_col(fill = "lightblue", alpha = 0.7) +
  labs(title = "Location Diversity by Subject (Shannon Entropy)",
       x = "Subject ID", y = "Shannon Entropy") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Combine Plot 2 panels
plot2 <- (p2a | p2b) / (p2c | p2d)
plot2 <- plot2 + plot_annotation(title = "Plot 2: Individual Differences in Activity and Location Patterns")

print(plot2)
```