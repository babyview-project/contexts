{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from vendi_score import vendi\n",
    "from pprint import pprint   \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1094223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Set this to either images or videos\n",
    "images_or_videos = 'images'  # 'images' or 'videos'\n",
    "\n",
    "if images_or_videos == 'videos':\n",
    "    embedding_model = 'facebook_vjepa2-vitl-fpc64-256'\n",
    "    embedding_dir_dict = {\n",
    "        'BabyView': f'/ccn2a/dataset/babyview/2025.2/outputs/video_embeddings/babyview/{embedding_model}',\n",
    "        'SAYCam': f'/ccn2a/dataset/babyview/2025.2/outputs/video_embeddings/SAYCam/{embedding_model}',\n",
    "        'Kinetics400': f'/ccn2a/dataset/babyview/2025.2/outputs/video_embeddings/kinetics_train//{embedding_model}',\n",
    "        'Ego4D': f'/ccn2a/dataset/babyview/2025.2/outputs/video_embeddings/ego4D/{embedding_model}',\n",
    "        'SSv2': f'/ccn2a/dataset/babyview/2025.2/outputs/video_embeddings/ssv2/{embedding_model}',\n",
    "        'MomentsInTime': f'/ccn2a/dataset/babyview/2025.2/outputs/video_embeddings/Moments_in_Time_Raw_training/{embedding_model}',\n",
    "        'Physion': f'/ccn2a/dataset/babyview/2025.2/outputs/video_embeddings/physion/{embedding_model}',\n",
    "    }\n",
    "    \n",
    "elif images_or_videos == 'images':\n",
    "    embedding_model = 'facebook_dinov3-vitb16-pretrain-lvd1689m'\n",
    "    # embedding_model = 'facebook_dinov2-base'\n",
    "    embedding_dir_dict = {\n",
    "        'BabyView': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/babyview/{embedding_model}',\n",
    "        'SAYCam': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/SAYCam/{embedding_model}',\n",
    "        'Kinetics400': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/kinetics400_train//{embedding_model}',\n",
    "        'Ego4D': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/ego4D/{embedding_model}',\n",
    "        'SSv2': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/ssv2/{embedding_model}',\n",
    "        'MomentsInTime': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/Moments_in_Time_Raw_training/{embedding_model}',\n",
    "        'Physion': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/physion/{embedding_model}',\n",
    "        'ImageNet': f'/ccn2a/dataset/babyview/2025.2/outputs/image_embeddings/imagenet_test/{embedding_model}',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_files(embedding_dir):\n",
    "    files = [f for f in os.listdir(embedding_dir) if f.endswith(\".npy\")]\n",
    "    return len(files)\n",
    "\n",
    "def load_embeddings(embedding_dir, num_samples=1000):\n",
    "    files = [f for f in os.listdir(embedding_dir) if f.endswith(\".npy\")]\n",
    "    files = np.random.choice(files, min(num_samples, len(files)), replace=False)\n",
    "    X = np.stack([np.load(os.path.join(embedding_dir, f)) for f in files])  # (n, d)\n",
    "    \n",
    "    # # --- Z-score each column (feature) separately: X := (X - mean_col) / std_col ---\n",
    "    # # mean_col, std_col have shape (1, d) so broadcasting works on (n, d).\n",
    "    # mean_col = np.mean(X, axis=0, keepdims=True)\n",
    "    # std_col = np.std(X, axis=0, keepdims=True)  # population std (ddof=0); use ddof=1 if you prefer sample std\n",
    "    # std_col_safe = np.where(std_col < 1e-6, 1.0, std_col)  # replace small std with 1.0 to avoid division by zero\n",
    "    # X = (X - mean_col) / std_col_safe\n",
    "    # print('X:', X.shape)\n",
    "    return X\n",
    "\n",
    "def get_vendi_score(X): # score_dual uses the covariance (d×d) — fast & stable for normalized embeddings\n",
    "    vs = vendi.score_dual(X, normalize=True)  # set normalize=True if rows aren’t L2-normalized\n",
    "    return vs\n",
    "\n",
    "def get_cosine_distance_score(X):\n",
    "    sims = cosine_similarity(X)  # (n, n)\n",
    "    mean_sim = np.mean(sims[np.triu_indices(len(sims), k=1)])  # mean of upper triangle, excluding diagonal\n",
    "    return 1 - mean_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "embedding_dim = None\n",
    "for dataset_name, embedding_dir in embedding_dir_dict.items():\n",
    "    X = load_embeddings(embedding_dir)          # (n, 1024)\n",
    "    embedding_dim = X.shape[1]\n",
    "    num_files = get_num_files(embedding_dir)\n",
    "\n",
    "    # Get scores\n",
    "    vs = get_vendi_score(X) \n",
    "    cos_dist_score = get_cosine_distance_score(X)\n",
    "    \n",
    "    results[dataset_name] = {\n",
    "        'num_files': num_files,\n",
    "        'vendi_score': vs,\n",
    "        'cosine_distance': cos_dist_score,\n",
    "    }\n",
    "    print(f'{dataset_name}: {num_files} files, Vendi score: {vs}, Cosine distance: {cos_dist_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c55e81",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfed9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Results → DataFrame -----------------------------------------------------\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\").reset_index()\n",
    "df = df.rename(columns={\"index\": \"dataset\"})\n",
    "print(df)\n",
    "\n",
    "# (Optional) If all datasets used the same sample size in load_embeddings(),\n",
    "# Vendi is directly comparable. If NOT, normalize by the sample size you used.\n",
    "# Example, if you stored it: df[\"vendi_norm\"] = df[\"vendi_score\"] / df[\"n_used\"]\n",
    "\n",
    "# ---- 1) Scatter: Vendi vs cosine distance -----------------------------------\n",
    "plt.figure()\n",
    "plt.scatter(df[\"vendi_score\"], df[\"cosine_distance\"])\n",
    "for _, row in df.iterrows():\n",
    "    plt.annotate(row[\"dataset\"], (row[\"vendi_score\"], row[\"cosine_distance\"]), fontsize=8,\n",
    "                 xytext=(3, 3), textcoords=\"offset points\")\n",
    "plt.xlabel(\"Vendi score (↑ = more diverse)\")\n",
    "plt.ylabel(\"Mean cosine distance (↑ = more diverse)\")\n",
    "plt.title(f\"Video Embedding diversity: {embedding_model}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b5d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccwm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
